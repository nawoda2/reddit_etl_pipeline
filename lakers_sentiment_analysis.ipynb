{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lakers Sentiment Analysis & Player Mention Analysis\n",
        "\n",
        "## Comprehensive Analysis of Reddit Data with NER for Lakers Players\n",
        "\n",
        "This notebook provides a comprehensive analysis of Lakers-related Reddit data, including:\n",
        "- Sentiment analysis of posts and comments\n",
        "- Named Entity Recognition (NER) for Lakers players\n",
        "- Player-specific mention analysis\n",
        "- Correlation analysis between sentiment and player performance\n",
        "- Visualization and insights\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data manipulation and analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Database connectivity\n",
        "import psycopg2\n",
        "from sqlalchemy import create_engine, text\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add project root to path\n",
        "sys.path.insert(0, os.path.dirname(os.path.abspath('.')))\n",
        "\n",
        "# Project imports\n",
        "from data_processors.database_manager import DatabaseManager\n",
        "from data_processors.ner_processor import LakersNERProcessor\n",
        "from utils.lakers_roster import LAKERS_ROSTER, get_all_player_aliases\n",
        "from utils.constants import DATABASE_HOST, DATABASE_NAME, DATABASE_PORT, DATABASE_USER, DATABASE_PASSWORD\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as pyo\n",
        "pyo.init_notebook_mode(connected=True)\n",
        "\n",
        "# Statistical analysis\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Text analysis\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download required NLTK data\n",
        "try:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    nltk.download('vader_lexicon', quiet=True)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(f\"üìä Available Lakers players: {len(LAKERS_ROSTER)}\")\n",
        "print(f\"üîç Player aliases loaded: {len(get_all_player_aliases())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Database Connection and Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize database manager and NER processor\n",
        "db_manager = DatabaseManager()\n",
        "ner_processor = LakersNERProcessor()\n",
        "\n",
        "print(\"üîå Database connection established\")\n",
        "print(\"üß† NER processor initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Reddit posts data\n",
        "posts_query = \"\"\"\n",
        "SELECT \n",
        "    id, title, selftext, author, subreddit, score, num_comments, \n",
        "    upvote_ratio, created_utc, over_18, edited, spoiler, stickied\n",
        "FROM reddit_posts \n",
        "ORDER BY created_utc DESC\n",
        "\"\"\"\n",
        "\n",
        "with db_manager.engine.connect() as conn:\n",
        "    posts_df = pd.read_sql(posts_query, conn)\n",
        "\n",
        "print(f\"üìù Loaded {len(posts_df)} Reddit posts\")\n",
        "print(f\"üìÖ Date range: {posts_df['created_utc'].min()} to {posts_df['created_utc'].max()}\")\n",
        "posts_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Reddit comments data\n",
        "comments_query = \"\"\"\n",
        "SELECT \n",
        "    id, post_id, author, body, score, created_utc, \n",
        "    parent_id, is_submitter, edited\n",
        "FROM reddit_comments \n",
        "ORDER BY created_utc DESC\n",
        "\"\"\"\n",
        "\n",
        "with db_manager.engine.connect() as conn:\n",
        "    comments_df = pd.read_sql(comments_query, conn)\n",
        "\n",
        "print(f\"üí¨ Loaded {len(comments_df)} Reddit comments\")\n",
        "print(f\"üìÖ Date range: {comments_df['created_utc'].min()} to {comments_df['created_utc'].max()}\")\n",
        "comments_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load sentiment analysis data\n",
        "sentiment_query = \"\"\"\n",
        "SELECT \n",
        "    post_id, player_name, vader_positive, vader_negative, vader_neutral, vader_compound,\n",
        "    transformer_positive, transformer_negative, transformer_neutral, transformer_sentiment,\n",
        "    analysis_timestamp\n",
        "FROM sentiment_scores \n",
        "ORDER BY analysis_timestamp DESC\n",
        "\"\"\"\n",
        "\n",
        "with db_manager.engine.connect() as conn:\n",
        "    sentiment_df = pd.read_sql(sentiment_query, conn)\n",
        "\n",
        "print(f\"üòä Loaded {len(sentiment_df)} sentiment analysis records\")\n",
        "print(f\"üë• Unique players mentioned: {sentiment_df['player_name'].nunique()}\")\n",
        "sentiment_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Named Entity Recognition (NER) Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process posts for player mentions\n",
        "print(\"üîç Processing posts for player mentions...\")\n",
        "processed_posts, post_mentions = ner_processor.process_reddit_posts(posts_df)\n",
        "\n",
        "print(f\"‚úÖ Found {len(post_mentions)} player mentions in posts\")\n",
        "print(f\"üìä Mentions by player:\")\n",
        "if not post_mentions.empty:\n",
        "    mention_summary = post_mentions['player_name'].value_counts()\n",
        "    print(mention_summary.head(10))\n",
        "else:\n",
        "    print(\"No player mentions found in posts\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process comments for player mentions\n",
        "print(\"üîç Processing comments for player mentions...\")\n",
        "processed_comments, comment_mentions = ner_processor.process_reddit_comments(comments_df)\n",
        "\n",
        "print(f\"‚úÖ Found {len(comment_mentions)} player mentions in comments\")\n",
        "print(f\"üìä Mentions by player:\")\n",
        "if not comment_mentions.empty:\n",
        "    comment_mention_summary = comment_mentions['player_name'].value_counts()\n",
        "    print(comment_mention_summary.head(10))\n",
        "else:\n",
        "    print(\"No player mentions found in comments\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine all mentions\n",
        "all_mentions = pd.concat([post_mentions, comment_mentions], ignore_index=True)\n",
        "print(f\"üìä Total player mentions: {len(all_mentions)}\")\n",
        "print(f\"üë• Unique players mentioned: {all_mentions['player_name'].nunique()}\")\n",
        "\n",
        "# Display top mentioned players\n",
        "if not all_mentions.empty:\n",
        "    top_players = all_mentions['player_name'].value_counts().head(15)\n",
        "    print(\"\\nüèÜ Top 15 Most Mentioned Players:\")\n",
        "    for player, count in top_players.items():\n",
        "        print(f\"  {player}: {count} mentions\")\n",
        "else:\n",
        "    print(\"No mentions found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Player-Specific Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create player-specific analysis function\n",
        "def analyze_player_mentions(player_name, mentions_df, posts_df, comments_df):\n",
        "    \"\"\"\n",
        "    Comprehensive analysis for a specific player\n",
        "    \"\"\"\n",
        "    player_mentions = mentions_df[mentions_df['player_name'] == player_name].copy()\n",
        "    \n",
        "    if player_mentions.empty:\n",
        "        return {\n",
        "            'player_name': player_name,\n",
        "            'total_mentions': 0,\n",
        "            'post_mentions': 0,\n",
        "            'comment_mentions': 0,\n",
        "            'avg_confidence': 0,\n",
        "            'contexts': [],\n",
        "            'sentiment_data': pd.DataFrame()\n",
        "        }\n",
        "    \n",
        "    # Separate post and comment mentions\n",
        "    post_mentions = player_mentions[player_mentions['post_id'].notna()]\n",
        "    comment_mentions = player_mentions[player_mentions['comment_id'].notna()]\n",
        "    \n",
        "    # Get sentiment data for this player\n",
        "    player_sentiment = sentiment_df[sentiment_df['player_name'] == player_name]\n",
        "    \n",
        "    return {\n",
        "        'player_name': player_name,\n",
        "        'total_mentions': len(player_mentions),\n",
        "        'post_mentions': len(post_mentions),\n",
        "        'comment_mentions': len(comment_mentions),\n",
        "        'avg_confidence': player_mentions['confidence'].mean(),\n",
        "        'contexts': player_mentions['context'].tolist(),\n",
        "        'sentiment_data': player_sentiment\n",
        "    }\n",
        "\n",
        "# Analyze each Lakers player\n",
        "player_analyses = {}\n",
        "for player_name in LAKERS_ROSTER.keys():\n",
        "    player_analyses[player_name] = analyze_player_mentions(\n",
        "        player_name, all_mentions, posts_df, comments_df\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Player analysis completed for all Lakers players\")\n",
        "print(f\"üìä Players with mentions: {sum(1 for p in player_analyses.values() if p['total_mentions'] > 0)}\")\n",
        "print(f\"üìä Players without mentions: {sum(1 for p in player_analyses.values() if p['total_mentions'] == 0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive player summary\n",
        "player_summary_data = []\n",
        "for player_name, analysis in player_analyses.items():\n",
        "    player_info = LAKERS_ROSTER[player_name]\n",
        "    \n",
        "    # Calculate sentiment metrics if available\n",
        "    sentiment_metrics = {}\n",
        "    if not analysis['sentiment_data'].empty:\n",
        "        sentiment_data = analysis['sentiment_data']\n",
        "        sentiment_metrics = {\n",
        "            'avg_vader_compound': sentiment_data['vader_compound'].mean(),\n",
        "            'avg_transformer_positive': sentiment_data['transformer_positive'].mean(),\n",
        "            'avg_transformer_negative': sentiment_data['transformer_negative'].mean(),\n",
        "            'positive_mentions': len(sentiment_data[sentiment_data['vader_compound'] > 0.05]),\n",
        "            'negative_mentions': len(sentiment_data[sentiment_data['vader_compound'] < -0.05]),\n",
        "            'neutral_mentions': len(sentiment_data[(sentiment_data['vader_compound'] >= -0.05) & \n",
        "                                                 (sentiment_data['vader_compound'] <= 0.05)])\n",
        "        }\n",
        "    \n",
        "    player_summary_data.append({\n",
        "        'player_name': player_name,\n",
        "        'position': player_info['position'],\n",
        "        'jersey_number': player_info['jersey_number'],\n",
        "        'total_mentions': analysis['total_mentions'],\n",
        "        'post_mentions': analysis['post_mentions'],\n",
        "        'comment_mentions': analysis['comment_mentions'],\n",
        "        'avg_confidence': analysis['avg_confidence'],\n",
        "        **sentiment_metrics\n",
        "    })\n",
        "\n",
        "player_summary_df = pd.DataFrame(player_summary_data)\n",
        "player_summary_df = player_summary_df.fillna(0)\n",
        "\n",
        "print(\"üìä Lakers Player Mention Summary:\")\n",
        "print(player_summary_df.sort_values('total_mentions', ascending=False).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualization Dashboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualization dashboard\n",
        "fig = make_subplots(\n",
        "    rows=3, cols=2,\n",
        "    subplot_titles=(\n",
        "        'Player Mention Frequency',\n",
        "        'Sentiment Distribution',\n",
        "        'Player Sentiment Scores',\n",
        "        'Mention Confidence Distribution',\n",
        "        'Post vs Comment Mentions',\n",
        "        'Sentiment Over Time'\n",
        "    ),\n",
        "    specs=[[{\"type\": \"bar\"}, {\"type\": \"histogram\"}],\n",
        "           [{\"type\": \"bar\"}, {\"type\": \"histogram\"}],\n",
        "           [{\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
        ")\n",
        "\n",
        "# 1. Player Mention Frequency\n",
        "if not all_mentions.empty:\n",
        "    mention_counts = all_mentions['player_name'].value_counts().head(10)\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=mention_counts.index, y=mention_counts.values, name=\"Mentions\"),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "# 2. Sentiment Distribution\n",
        "if not sentiment_df.empty:\n",
        "    fig.add_trace(\n",
        "        go.Histogram(x=sentiment_df['vader_compound'], name=\"Vader Compound\"),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# 3. Player Sentiment Scores\n",
        "if not sentiment_df.empty:\n",
        "    player_sentiment = sentiment_df.groupby('player_name')['vader_compound'].mean().sort_values(ascending=False).head(10)\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=player_sentiment.index, y=player_sentiment.values, name=\"Avg Sentiment\"),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# 4. Mention Confidence Distribution\n",
        "if not all_mentions.empty:\n",
        "    fig.add_trace(\n",
        "        go.Histogram(x=all_mentions['confidence'], name=\"Confidence\"),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "# 5. Post vs Comment Mentions\n",
        "if not all_mentions.empty:\n",
        "    post_mentions_count = len(all_mentions[all_mentions['post_id'].notna()])\n",
        "    comment_mentions_count = len(all_mentions[all_mentions['comment_id'].notna()])\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Bar(x=['Posts', 'Comments'], y=[post_mentions_count, comment_mentions_count], name=\"Mention Type\"),\n",
        "        row=3, col=1\n",
        "    )\n",
        "\n",
        "# 6. Sentiment Over Time\n",
        "if not sentiment_df.empty:\n",
        "    sentiment_df['date'] = pd.to_datetime(sentiment_df['analysis_timestamp']).dt.date\n",
        "    daily_sentiment = sentiment_df.groupby('date')['vader_compound'].mean().reset_index()\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=daily_sentiment['date'], y=daily_sentiment['vader_compound'], \n",
        "                  mode='lines+markers', name=\"Daily Sentiment\"),\n",
        "        row=3, col=2\n",
        "    )\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    height=1200,\n",
        "    title_text=\"Lakers Sentiment Analysis Dashboard\",\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Export Results and Summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
