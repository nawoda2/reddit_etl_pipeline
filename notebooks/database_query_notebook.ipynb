{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reddit ETL Pipeline - Database Query Notebook\n",
        "\n",
        "This notebook allows you to query the PostgreSQL database used by the Reddit ETL pipeline.\n",
        "\n",
        "## Database Connection Details\n",
        "- **Configuration**: Loaded from `../config/config.conf`\n",
        "- **Security**: No hardcoded credentials in the notebook\n",
        "- **Environment**: Uses the same config as the ETL pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n",
            "Current directory: c:\\Users\\nawod\\Desktop\\reddit_etl_pipeline\\notebooks\n",
            "Parent directory added to path: c:\\Users\\nawod\\Desktop\\reddit_etl_pipeline\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "from sqlalchemy import create_engine\n",
        "import configparser\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add parent directory to path to access config and utils\n",
        "current_dir = os.getcwd()\n",
        "parent_dir = os.path.dirname(current_dir)\n",
        "if parent_dir not in sys.path:\n",
        "    sys.path.insert(0, parent_dir)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Current directory: {current_dir}\")\n",
        "print(f\"Parent directory added to path: {parent_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Database configuration loaded using config loader utility!\n",
            "üìä Connected to: reddit-etl-db.cfu0u0e26k4w.us-west-1.rds.amazonaws.com:5432/airflow_reddit\n",
            "üîí Using secure configuration loading (no hardcoded credentials)\n"
          ]
        }
      ],
      "source": [
        "# Load database configuration using the project's config loader\n",
        "def load_database_config():\n",
        "    \"\"\"Load database configuration with fallback methods\"\"\"\n",
        "    \n",
        "    # Method 1: Try using the config loader utility\n",
        "    try:\n",
        "        from utils.config_loader import load_config\n",
        "        config = load_config('../config/config.conf')\n",
        "        db_config = config.get_database_config()\n",
        "        connection_string = config.get_connection_string()\n",
        "        print(\"‚úÖ Database configuration loaded using config loader utility!\")\n",
        "        return db_config, connection_string\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Config loader failed: {e}\")\n",
        "    \n",
        "    # Method 2: Fallback to direct config file reading\n",
        "    try:\n",
        "        config = configparser.ConfigParser()\n",
        "        config_path = '../config/config.conf'\n",
        "        \n",
        "        if not os.path.exists(config_path):\n",
        "            raise FileNotFoundError(f\"Config file not found at {config_path}\")\n",
        "        \n",
        "        config.read(config_path)\n",
        "        \n",
        "        db_config = {\n",
        "            'host': config.get('database', 'database_host'),\n",
        "            'database': config.get('database', 'database_name'),\n",
        "            'user': config.get('database', 'database_username'),\n",
        "            'password': config.get('database', 'database_password'),\n",
        "            'port': config.getint('database', 'database_port')\n",
        "        }\n",
        "        \n",
        "        connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
        "        \n",
        "        print(\"‚úÖ Database configuration loaded using direct config file reading!\")\n",
        "        return db_config, connection_string\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå All configuration loading methods failed: {e}\")\n",
        "        raise\n",
        "\n",
        "# Load configuration\n",
        "try:\n",
        "    DB_CONFIG, connection_string = load_database_config()\n",
        "    print(f\"üìä Connected to: {DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\")\n",
        "    print(\"üîí Using secure configuration loading (no hardcoded credentials)\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading database configuration: {e}\")\n",
        "    print(\"Make sure you're running this notebook from the notebooks/ directory\")\n",
        "    print(\"and that ../config/config.conf exists\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Database connection successful!\n",
            "üìä Database Version: PostgreSQL 17.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 12.4.0, 64-bit\n"
          ]
        }
      ],
      "source": [
        "# Test database connection\n",
        "try:\n",
        "    # Test with psycopg2\n",
        "    conn = psycopg2.connect(**DB_CONFIG)\n",
        "    print(\"‚úÖ Database connection successful!\")\n",
        "    \n",
        "    # Get database info\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT version();\")\n",
        "    db_version = cursor.fetchone()[0]\n",
        "    print(f\"üìä Database Version: {db_version}\")\n",
        "    \n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Database connection failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ SQLAlchemy engine created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create SQLAlchemy engine for pandas integration\n",
        "try:\n",
        "    engine = create_engine(connection_string)\n",
        "    print(\"‚úÖ SQLAlchemy engine created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå SQLAlchemy engine creation failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Overview\n",
        "\n",
        "The notebook uses the same configuration file as the ETL pipeline. Here's what's available:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Available Configuration Sections (using config loader):\n",
            "============================================================\n",
            "üìä Database: reddit-etl-db.cfu0u0e26k4w.us-west-1.rds.amazonaws.com:5432/airflow_reddit\n",
            "‚òÅÔ∏è  AWS Region: us-west-1\n",
            "ü™£ S3 Bucket: lakers-project\n",
            "üîó Reddit Client ID: NO8qdjq4...\n",
            "üìÅ Output Path: /opt/airflow/data/output\n",
            "‚öôÔ∏è  Batch Size: 1000\n",
            "üìù Log Level: INFO\n",
            "\n",
            "‚úÖ All configuration loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Display available configuration sections\n",
        "def display_config_overview():\n",
        "    \"\"\"Display configuration overview with fallback methods\"\"\"\n",
        "    \n",
        "    # Method 1: Try using the config loader utility\n",
        "    try:\n",
        "        from utils.config_loader import load_config\n",
        "        config = load_config('../config/config.conf')\n",
        "        \n",
        "        print(\"üîß Available Configuration Sections (using config loader):\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        # Database config\n",
        "        db_config = config.get_database_config()\n",
        "        print(f\"üìä Database: {db_config['host']}:{db_config['port']}/{db_config['database']}\")\n",
        "        \n",
        "        # AWS config\n",
        "        aws_config = config.get_aws_config()\n",
        "        print(f\"‚òÅÔ∏è  AWS Region: {aws_config['region']}\")\n",
        "        print(f\"ü™£ S3 Bucket: {aws_config['bucket_name']}\")\n",
        "        \n",
        "        # Reddit config\n",
        "        reddit_config = config.get_reddit_config()\n",
        "        print(f\"üîó Reddit Client ID: {reddit_config['client_id'][:8]}...\")\n",
        "        \n",
        "        # File paths\n",
        "        file_paths = config.get_file_paths()\n",
        "        print(f\"üìÅ Output Path: {file_paths['output_path']}\")\n",
        "        \n",
        "        # ETL settings\n",
        "        etl_settings = config.get_etl_settings()\n",
        "        print(f\"‚öôÔ∏è  Batch Size: {etl_settings['batch_size']}\")\n",
        "        print(f\"üìù Log Level: {etl_settings['log_level']}\")\n",
        "        \n",
        "        print(\"\\n‚úÖ All configuration loaded successfully!\")\n",
        "        return\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Config loader failed: {e}\")\n",
        "    \n",
        "    # Method 2: Fallback to basic database config display\n",
        "    try:\n",
        "        print(\"üîß Basic Configuration Overview (fallback method):\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"üìä Database: {DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\")\n",
        "        print(\"‚ÑπÔ∏è  For full configuration details, ensure utils/config_loader.py is accessible\")\n",
        "        print(\"\\n‚úÖ Basic configuration loaded successfully!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error displaying configuration: {e}\")\n",
        "\n",
        "# Display configuration overview\n",
        "display_config_overview()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Database Schema Exploration\n",
        "\n",
        "Let's explore what tables exist in the database.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Available Tables:\n",
            "                           table_name\n",
            "0                correlation_analysis\n",
            "1                          dim_author\n",
            "2                            dim_date\n",
            "3                          dim_player\n",
            "4                            dim_post\n",
            "5              fact_comment_sentiment\n",
            "6       fact_comment_sentiment_simple\n",
            "7                fact_player_mentions\n",
            "8                 fact_post_sentiment\n",
            "9          fact_post_sentiment_simple\n",
            "10                    player_mentions\n",
            "11      player_mentions_austin_reaves\n",
            "12       player_mentions_bronny_james\n",
            "13   player_mentions_christian_koloko\n",
            "14      player_mentions_deandre_ayton\n",
            "15       player_mentions_gabe_vincent\n",
            "16       player_mentions_jake_laravia\n",
            "17  player_mentions_jarred_vanderbilt\n",
            "18       player_mentions_jaxson_hayes\n",
            "19     player_mentions_jordan_goodwin\n",
            "20       player_mentions_lebron_james\n",
            "21        player_mentions_luka_donciƒá\n",
            "22       player_mentions_marcus_smart\n",
            "23        player_mentions_maxi_kleber\n",
            "24      player_mentions_rui_hachimura\n",
            "25                 player_performance\n",
            "26                    reddit_comments\n",
            "27                       reddit_posts\n",
            "28                   sentiment_scores\n",
            "29      vw_comment_sentiment_analysis\n",
            "30       vw_comment_sentiment_summary\n",
            "31       vw_overall_sentiment_summary\n",
            "32         vw_player_mentions_summary\n",
            "33         vw_post_sentiment_analysis\n",
            "34          vw_post_sentiment_summary\n"
          ]
        }
      ],
      "source": [
        "# List all tables in the database\n",
        "query_tables = \"\"\"\n",
        "SELECT table_name \n",
        "FROM information_schema.tables \n",
        "WHERE table_schema = 'public'\n",
        "ORDER BY table_name;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    tables_df = pd.read_sql(query_tables, engine)\n",
        "    print(\"üìã Available Tables:\")\n",
        "    print(tables_df)\n",
        "    \n",
        "    if len(tables_df) == 0:\n",
        "        print(\"\\n‚ö†Ô∏è  No tables found in the public schema.\")\n",
        "        print(\"This might mean the ETL pipeline hasn't run yet or data hasn't been loaded.\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error listing tables: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample Queries\n",
        "\n",
        "Here are some sample queries you can run. Modify them as needed for your analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Reddit Posts Sample Data:\n",
            "        id                                              title selftext  \\\n",
            "0  1o1drvz            By Creative Director Natalia Bryant üíúüíõüêç            \n",
            "1  1o1idr4                                         my heart ü•π            \n",
            "2  1o1gy0k     Natalia Bryant X Brenda Song behind the scenes            \n",
            "3  1o11er4                           Luka's new IG post - \"üß©\"            \n",
            "4  1o1niml  Ayton was asked what it's been like working wi...            \n",
            "\n",
            "           author subreddit  score  num_comments         created_utc  \\\n",
            "0   MamiTarantina    lakers    944            54 2025-10-08 15:31:43   \n",
            "1    creamyglazed    lakers    759            35 2025-10-08 18:19:06   \n",
            "2   MamiTarantina    lakers    597            17 2025-10-08 17:27:11   \n",
            "3     Kang_Burger    lakers    569            34 2025-10-08 04:51:30   \n",
            "4  WittyKittieKat    lakers    407           168 2025-10-08 21:12:18   \n",
            "\n",
            "                                    url  upvote_ratio  over_18  edited  \\\n",
            "0       https://v.redd.it/zbkgphirpwtf1          0.98    False   False   \n",
            "1   https://i.redd.it/9ukubt1ljxtf1.png          0.99    False   False   \n",
            "2  https://i.redd.it/b8ktlgkdaxtf1.jpeg          0.99    False   False   \n",
            "3  https://i.redd.it/70nzz2ujjttf1.jpeg          0.99    False   False   \n",
            "4         https://streamable.com/re4o44          0.99    False   False   \n",
            "\n",
            "   spoiler  stickied                 created_at  \n",
            "0    False     False 2025-10-09 00:28:51.176540  \n",
            "1    False     False 2025-10-09 00:28:51.176540  \n",
            "2    False     False 2025-10-09 00:28:51.176540  \n",
            "3    False     False 2025-10-09 00:28:51.176540  \n",
            "4    False     False 2025-10-09 00:28:51.176540  \n",
            "\n",
            "üìà Total rows: 5\n"
          ]
        }
      ],
      "source": [
        "# Query 1: Check if reddit_posts table exists and get sample data\n",
        "query_reddit_posts = \"\"\"\n",
        "SELECT * \n",
        "FROM reddit_posts \n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    reddit_posts_df = pd.read_sql(query_reddit_posts, engine)\n",
        "    print(\"üìä Reddit Posts Sample Data:\")\n",
        "    print(reddit_posts_df)\n",
        "    print(f\"\\nüìà Total rows: {len(reddit_posts_df)}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error querying reddit_posts: {e}\")\n",
        "    print(\"This table might not exist yet. Run the ETL pipeline first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Sentiment Analysis Sample Data:\n",
            "   id  post_id    player_name  vader_positive  vader_negative  vader_neutral  \\\n",
            "0  73  1o1idr4  austin_reaves           0.808             0.0          0.192   \n",
            "1  75  1o1niml         lebron           0.111             0.0          0.889   \n",
            "2  76  1o1k93c    kobe_bryant           0.000             0.0          1.000   \n",
            "3  77  1o1o4st         lebron           0.000             0.0          1.000   \n",
            "4  78  1o1e9tu     steve_nash           0.286             0.0          0.714   \n",
            "\n",
            "   vader_compound  transformer_positive  transformer_negative  \\\n",
            "0          0.8555              0.591608              0.066267   \n",
            "1          0.6124              0.094252              0.072383   \n",
            "2          0.0000              0.700267              0.021841   \n",
            "3          0.0000              0.076922              0.016278   \n",
            "4          0.5859              0.280669              0.008875   \n",
            "\n",
            "   transformer_neutral transformer_sentiment         analysis_timestamp  \\\n",
            "0             0.342125              positive 2025-10-08 18:14:57.433267   \n",
            "1             0.833366               neutral 2025-10-08 18:14:57.599479   \n",
            "2             0.277892              positive 2025-10-08 18:14:57.687102   \n",
            "3             0.906799               neutral 2025-10-08 18:14:57.732631   \n",
            "4             0.710455               neutral 2025-10-08 18:14:57.821216   \n",
            "\n",
            "                  created_at  \n",
            "0 2025-10-09 01:14:25.244259  \n",
            "1 2025-10-09 01:14:25.244259  \n",
            "2 2025-10-09 01:14:25.244259  \n",
            "3 2025-10-09 01:14:25.244259  \n",
            "4 2025-10-09 01:14:25.244259  \n",
            "\n",
            "üìà Total rows: 5\n"
          ]
        }
      ],
      "source": [
        "# Query 2: Check sentiment analysis results\n",
        "query_sentiment = \"\"\"\n",
        "SELECT * \n",
        "FROM sentiment_scores\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    sentiment_df = pd.read_sql(query_sentiment, engine)\n",
        "    print(\"üìä Sentiment Analysis Sample Data:\")\n",
        "    print(sentiment_df)\n",
        "    print(f\"\\nüìà Total rows: {len(sentiment_df)}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error querying sentiment_analysis: {e}\")\n",
        "    print(\"This table might not exist yet. Run the ETL pipeline first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Queries\n",
        "\n",
        "Use the cell below to run your own custom queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå Error running custom query: (psycopg2.errors.UndefinedColumn) column \"tablename\" does not exist\n",
            "LINE 5:     tablename,\n",
            "            ^\n",
            "\n",
            "[SQL: \n",
            "-- Example: Get all tables and their row counts\n",
            "SELECT \n",
            "    schemaname,\n",
            "    tablename,\n",
            "    n_tup_ins as inserts,\n",
            "    n_tup_upd as updates,\n",
            "    n_tup_del as deletes\n",
            "FROM pg_stat_user_tables\n",
            "ORDER BY tablename;\n",
            "]\n",
            "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
          ]
        }
      ],
      "source": [
        "# Custom Query - Modify this query as needed\n",
        "custom_query = \"\"\"\n",
        "-- Example: Get all tables and their row counts\n",
        "SELECT \n",
        "    schemaname,\n",
        "    tablename,\n",
        "    n_tup_ins as inserts,\n",
        "    n_tup_upd as updates,\n",
        "    n_tup_del as deletes\n",
        "FROM pg_stat_user_tables\n",
        "ORDER BY tablename;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    custom_df = pd.read_sql(custom_query, engine)\n",
        "    print(\"üìä Custom Query Results:\")\n",
        "    print(custom_df)\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error running custom query: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
